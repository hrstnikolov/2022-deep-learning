{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "278fcecf-141a-47e2-846c-7e1ce652ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a937f4b-8544-437b-a8ad-b5655d876fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac0188-2b73-4465-a33a-c153a20ff17a",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd1b150-14f7-4a70-acd2-d20f925d76e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Create initial resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "573338f7-55a8-4453-8a6f-e1931f9becad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50.ResNet50(include_top=True,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "218714f9-ee7c-471b-83a0-d79597dade65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "234f42fe-5632-43fb-90c2-1af351a04acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<keras.engine.input_layer.InputLayer at 0x1ae1a7a4e20>,\n",
       "  <keras.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x1ae164896d0>,\n",
       "  <keras.layers.convolutional.conv2d.Conv2D at 0x1ae0f271b20>],\n",
       " [<keras.layers.core.activation.Activation at 0x1ae1a5f97f0>,\n",
       "  <keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x1ae1a614040>,\n",
       "  <keras.layers.core.dense.Dense at 0x1ae187c0f10>])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[:3], model.layers[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b0b04fc-71e4-47b9-bce8-4ac93dd50c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 224, 224, 3]), TensorShape([None, 1000]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input.shape, model.output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e341a-f4aa-4ad9-bde5-dcc85e45f9b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Duplicate the resnet50 using `Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "830f658b-825b-485b-9d5b-bb7aa3fc3dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(inputs=model.input, outputs=model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4a1dd6d-32f6-42dd-add2-b01dc3cc289b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model2.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5e62630-b60a-47cd-871f-c22a055ab3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 224, 224, 3]), TensorShape([None, 1000]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.input.shape, model2.output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530dc9e-28d7-49a3-9163-b1efa84e27e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Extract resnet50 convolutional head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bd258a0-a644-49b9-85ee-251f3b0b71f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 2048) dtype=float32 (created by layer 'avg_pool')>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_but_one_layer_output = model.layers[-2].output\n",
    "last_but_one_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4343010-d0a5-47eb-9c84-8f95f4b2e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_head = Model(inputs=model.input, outputs=last_but_one_layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12a26700-c260-464b-8b19-afe25f00fc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conv_head.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44ff86c1-b210-452d-a337-605afdb9003d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 224, 224, 3]), TensorShape([None, 2048]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_head.input.shape, conv_head.output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c025cfd-8e0d-45ee-9da9-fba0bbcbbe24",
   "metadata": {},
   "source": [
    "The output shape has changed to the 2048-element vector that avg pooling outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ccd3fa-d031-45ac-b09c-8d33819f1303",
   "metadata": {},
   "source": [
    "## Heading\n",
    "\n",
    "Natural images dataset https://www.kaggle.com/datasets/prasunroy/natural-images\n",
    "\n",
    "The purpose is to use the brains of ResNet50, but classify the 8 classes in the Natural images dataset (instead of the 1000 classes in ResNet50's last layer).\n",
    "\n",
    "Two ways to **create models**, two Keras APIs to **connect models and layers**:\n",
    "- Keras Sequential API\n",
    "- Keras Functional API\n",
    "\n",
    "Keras Sequential API does not always work.\n",
    "\n",
    "\n",
    "See more here https://www.tensorflow.org/guide/keras/functional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7095b28-9b93-4127-a0d6-a7cb7a821f70",
   "metadata": {},
   "source": [
    "### Keras Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de7e9ccf-02c4-4293-9b46-c25c95722467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_1 (Functional)        (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 16392     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,604,104\n",
      "Trainable params: 23,550,984\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning model 1\n",
    "tl_model1 = Sequential([\n",
    "    conv_head,\n",
    "    Dense(8, activation='softmax'),\n",
    "])\n",
    "\n",
    "tl_model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d14a5-5584-4341-b12c-fab1a6a3a00a",
   "metadata": {},
   "source": [
    "### Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5420700-4307-4942-b488-1e96be0eb22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 8) dtype=float32 (created by layer 'dense_3')>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer = Dense(8, activation='softmax')\n",
    "\n",
    "# TypeError: Inputs to a layer should be tensors.\n",
    "# dense_layer(conv_head)\n",
    "\n",
    "# Correct\n",
    "dense_layer_output = dense_layer(conv_head.output)\n",
    "dense_layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0935964-a8d8-4413-8d6f-124ccbc9127f",
   "metadata": {},
   "source": [
    "### More functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec1ed66-c04e-4b2a-a62a-e05fd7b2775c",
   "metadata": {},
   "source": [
    "Add few more layers. Навързване."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2f1c230-8a47-452b-b774-72894c70bffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 9) dtype=float32 (created by layer 'dense_5')>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_intermediate = Dense(512, activation='relu')(conv_head.output)\n",
    "dropout_final = Dropout(0.2)(dense_intermediate)\n",
    "dense_final = Dense(9, activation='softmax')(dropout_final)\n",
    "\n",
    "dense_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b9875-9cf0-4887-acb5-c3462d7de9b4",
   "metadata": {},
   "source": [
    "## Freezing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f1658cc-21c5-4e50-9718-9e1c4a6611a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_1 (Functional)        (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 4104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,640,904\n",
      "Trainable params: 24,587,784\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_learning = Sequential([\n",
    "    conv_head,\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(8, activation='softmax'),\n",
    "])\n",
    "\n",
    "transfer_learning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a83157f-2151-475e-9e45-c9dfc09ab925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
